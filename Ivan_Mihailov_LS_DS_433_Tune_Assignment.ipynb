{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ivan_Mihailov_LS_DS_433_Tune_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "nteract": {
      "version": "0.22.4"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ivan-mihailov/LS-Unit-4-Sprint-2/blob/main/Ivan_Mihailov_LS_DS_433_Tune_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGGrt9EYlCqY"
      },
      "source": [
        "\n",
        "\n",
        "# Tune Practice\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2 Assignment 3*\n",
        "\n",
        "# Gridsearch Hyperparameters\n",
        "\n",
        "In the guided project, you learned how to use sklearn's GridsearchCV and keras-tuner library to tune the hyperparamters of a neural network model. For your module project you'll continue using these two libraries however we are going to make things a little more interesting for you. \n",
        "\n",
        "Continue to use TensorFlow Keras & a sample of the [Quickdraw dataset](https://github.com/googlecreativelab/quickdraw-dataset) to build a sketch classification model. The dataset has been sampled to only 10 classes and 10000 observations per class. \n",
        "\n",
        "\n",
        "\n",
        "**Don't forgot to switch to GPU on Colab!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-tDdeWYIIL7"
      },
      "source": [
        "!pip install keras-tuner"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8n23gwY3N8W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67b9f792-fbb2-42c1-99b4-b56c10f2aa49"
      },
      "source": [
        "# native python libraries imports \n",
        "import math\n",
        "from time import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# sklearn imports \n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# keras imports \n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from kerastuner.tuners import RandomSearch, BayesianOptimization, Sklearn\n",
        "from kerastuner.engine.hyperparameters import HyperParameters\n",
        "from tensorflow.keras.activations import relu, sigmoid, tanh, elu, selu\n",
        "from tensorflow.keras.optimizers import Adam, SGD, Nadam\n",
        "from tensorflow.keras.utils import get_file\n",
        "\n",
        "# required for compatibility between sklearn and keras\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFWONQCT3N8X"
      },
      "source": [
        "def load_quickdraw10():\n",
        "    \"\"\"\n",
        "    Function to load the Quickdraw10 dataset from Github repo; shuffle the data;\n",
        "    and perform a train/test split.\n",
        "    \"\"\"\n",
        "    \n",
        "    URL_ = \"https://github.com/LambdaSchool/DS-Unit-4-Sprint-2-Neural-Networks/blob/main/quickdraw10.npz?raw=true\"\n",
        "    \n",
        "    path_to_zip = get_file('./quickdraw10.npz', origin=URL_, extract=False)\n",
        "\n",
        "    data = np.load(path_to_zip)\n",
        "    \n",
        "    # normalize your image data\n",
        "    max_pixel_value = 255\n",
        "    X = data['arr_0']/max_pixel_value\n",
        "    Y = data['arr_1']\n",
        "        \n",
        "    return train_test_split(X, Y, shuffle=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJ1SPVDj3N8Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8f97c11-9eaf-468e-fada-f5d95924ab13"
      },
      "source": [
        "X_train, X_test, y_train, y_test = load_quickdraw10()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/LambdaSchool/DS-Unit-4-Sprint-2-Neural-Networks/blob/main/quickdraw10.npz?raw=true\n",
            "25427968/25421363 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-nfSRzG3N8Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00963dab-d332-4dbd-9f95-9582ba08f0aa"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(75000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4WNvI3V3N8Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45674d3c-c813-460b-e40e-9b4c453024f7"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(75000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJPir8nC3N8a"
      },
      "source": [
        "_____\n",
        "\n",
        "# Experiment 1\n",
        "\n",
        "## Tune Hyperperameters using Enhanced GridsearchCV \n",
        "\n",
        "We are going to use GridsearchCV again to tune a deep learning model however we are going to add some additional functionality to our gridsearch. Specifically, we are going to automate away the generation of how many nodes to use in a layer and how many layers to use in a model! \n",
        "\n",
        "By the way, yes, there is a function within a function. Try to not let that bother you. An alternative to this would be to create a class. If you're up for the challenge give it a shot. However, consider this a stretch goal that you come back to after you finish going through this assignment. \n",
        "\n",
        "\n",
        "### Objective \n",
        "\n",
        "The objective of this experiment is to show you how to automate the generation of layers and layer nodes for the purposes of gridsearch. Up until now, we've been manually selecting the number of layers and layer nodes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USXjs7Hk71Hy"
      },
      "source": [
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(n_layers,  first_layer_nodes, last_layer_nodes, act_funct =\"relu\", negative_node_incrementation=True):\n",
        "    \"\"\"\"\n",
        "    Returns a compiled keras model \n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    n_layers: int \n",
        "        number of hidden layers in model \n",
        "        To be clear, this excludes the input and output layer.\n",
        "        \n",
        "    first_layer_nodes: int\n",
        "        Number of nodes in the first hidden layer \n",
        "\n",
        "    last_layer_nodes: int\n",
        "        Number of nodes in the last hidden layer (this is the layer just prior to the output layer)\n",
        "        \n",
        "     act_funct: string \n",
        "         Name of activation function to use in hidden layers (this excludes the output layler)\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    model: keras object \n",
        "    \"\"\"\n",
        "    \n",
        "    def gen_layer_nodes(n_layers, first_layer_nodes, last_layer_nodes, negative_node_incrementation=True):\n",
        "        \"\"\"\n",
        "        Generates and returns the number of nodes in each hidden layer. \n",
        "        To be clear, this excludes the input and output layer. \n",
        "\n",
        "        Note\n",
        "        ----\n",
        "        Number of nodes in each layer is linearly incremented. \n",
        "        For example, gen_layer_nodes(5, 500, 100) will generate [500, 400, 300, 200, 100]\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_layers: int\n",
        "            Number of hidden layers\n",
        "            This values should be 2 or greater \n",
        "\n",
        "        first_layer_nodes: int\n",
        "\n",
        "        last_layer_nodes: int\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        layers: list of ints\n",
        "            Contains number of nodes for each layer \n",
        "        \"\"\"\n",
        "\n",
        "        # throws an error if n_layers is less than 2 \n",
        "        assert n_layers >= 2, \"n_layers must be 2 or greater\"\n",
        "\n",
        "        layers = []\n",
        "\n",
        "        # PROTIP: IF YOU WANT THE NODE INCREMENTATION TO BE SPACED DIFFERENTLY\n",
        "        # THEN YOU'LL NEED TO CHANGE THE WAY THAT IT'S CALCULATED - HAVE FUN!\n",
        "        # when set to True number of nodes are decreased for subsequent layers \n",
        "        if negative_node_incrementation:\n",
        "            # subtract this amount from previous layer's nodes in order to increment towards smaller numbers \n",
        "            nodes_increment = (last_layer_nodes - first_layer_nodes)/ (n_layers-1)\n",
        "            \n",
        "        # when set to False number of nodes are increased for subsequent layers\n",
        "        else:\n",
        "            # add this amount from previous layer's nodes in order to increment towards larger numbers \n",
        "            nodes_increment = (first_layer_nodes - last_layer_nodes)/ (n_layers-1)\n",
        "\n",
        "        nodes = first_layer_nodes\n",
        "\n",
        "        for i in range(1, n_layers+1):\n",
        "\n",
        "            layers.append(math.ceil(nodes))\n",
        "\n",
        "            # increment nodes for next layer \n",
        "            nodes = nodes + nodes_increment\n",
        "\n",
        "        return layers\n",
        "    \n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    \n",
        "    n_nodes = gen_layer_nodes(n_layers, first_layer_nodes, last_layer_nodes, negative_node_incrementation)\n",
        "    \n",
        "    for i in range(1, n_layers):\n",
        "        if i==1:\n",
        "            model.add(Dense(first_layer_nodes, input_dim=X_train.shape[1], activation=act_funct))\n",
        "        else:\n",
        "            model.add(Dense(n_nodes[i-1], activation=act_funct))\n",
        "            \n",
        "            \n",
        "    # output layer \n",
        "    model.add(Dense(10, # 10 unit/neurons in output layer because we have 10 possible labels to predict  \n",
        "                    activation='softmax')) # use softmax for a label set greater than 2            \n",
        "    \n",
        "    # Compile model\n",
        "    model.compile(loss='sparse_categorical_crossentropy', \n",
        "                  optimizer='adam', # adam is a good default optimizer \n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    # do not include model.fit() inside the create_model function\n",
        "    # KerasClassifier is expecting a complied model \n",
        "    return model\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsDOjzL43N8d"
      },
      "source": [
        "## Explore create_model\n",
        "\n",
        "Let's build a few different models in order to understand how the above code works in practice. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Omdr9J2-3N8e"
      },
      "source": [
        "### Build model \n",
        "\n",
        "Use `create_model` to build a model. \n",
        "\n",
        "- Set `n_layers = 10` \n",
        "- Set `first_layer_nodes = 500`\n",
        "- Set `last_layer_nodes = 100`\n",
        "- Set `act_funct = \"relu\"`\n",
        "- Make sure that `negative_node_incrementation = True`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "5dcf5c585f07629a03086cf57ba53615",
          "grade": false,
          "grade_id": "cell-86d63e89a21223de",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "_mt50ymO3N8e"
      },
      "source": [
        "# use create_model to create a model \n",
        "\n",
        "# YOUR CODE HERE\n",
        "model = create_model(n_layers = 10, first_layer_nodes = 500, \n",
        "                     last_layer_nodes = 100, act_funct = 'relu', \n",
        "                     negative_node_incrementation = True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3z14ddvV3N8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78f4c0c4-da3e-4958-b2a4-1f52fa79ee61"
      },
      "source": [
        "# run model.summary() and make sure that you understand the model architecture that you just built \n",
        "# Notice in the model summary how the number of nodes have been linearly incremented in decreasing values. \n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 500)               392500    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 456)               228456    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 412)               188284    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 367)               151571    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 323)               118864    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 278)               90072     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 234)               65286     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 189)               44415     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 145)               27550     \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                1460      \n",
            "=================================================================\n",
            "Total params: 1,308,458\n",
            "Trainable params: 1,308,458\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzxn0hOs3N8f"
      },
      "source": [
        "### Build model \n",
        "\n",
        "Use `create_model` to build a model. \n",
        "\n",
        "- Set `n_layers = 10` \n",
        "- Set `first_layer_nodes = 500`\n",
        "- Set `last_layer_nodes = 100`\n",
        "- Set `act_funct = \"relu\"`\n",
        "- Make sure that `negative_node_incrementation = False`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "e0722533c325d699f4842e874e43720e",
          "grade": false,
          "grade_id": "cell-99d563a291231a7b",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "9p7hSiIn3N8g"
      },
      "source": [
        "# use create_model to create a model \n",
        "\n",
        "# YOUR CODE HERE\n",
        "model = create_model(n_layers = 10, first_layer_nodes = 500, \n",
        "                     last_layer_nodes = 100, act_funct = 'relu', \n",
        "                     negative_node_incrementation = False)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNuZsntK3N8g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f3032a8-a211-4ec0-faec-967abe9880bc"
      },
      "source": [
        "# run model.summary() and make sure that you understand the model architecture that you just built \n",
        "# Notice in the model summary how the number of nodes have been linearly incremented in increasing values.\n",
        "# The output layer must have 10 nodes because there are 10 labels to predict \n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_10 (Dense)             (None, 500)               392500    \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 545)               273045    \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 589)               321594    \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 634)               374060    \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 678)               430530    \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 723)               490917    \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 767)               555308    \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 812)               623616    \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 856)               695928    \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 10)                8570      \n",
            "=================================================================\n",
            "Total params: 4,166,068\n",
            "Trainable params: 4,166,068\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2_mJf3T3N8g"
      },
      "source": [
        "# feel free to play around with parameters to gain additional insight as to how the create_model function works \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_IScH3c3N8g"
      },
      "source": [
        "Ok, now that we've played around a bit with  `create_model` in order to understand how it works, let's build a much simpler model that we'll be running gridsearches. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZ7Gxs063N8h"
      },
      "source": [
        "### Build model \n",
        "\n",
        "Use `create_model` to build a model. \n",
        "\n",
        "- Set `n_layers = 2` \n",
        "- Set `first_layer_nodes = 500`\n",
        "- Set `last_layer_nodes = 100`\n",
        "- Set `act_funct = \"relu\"`\n",
        "- Make sure that `negative_node_incrementation = True`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "606b85d0ba4531836f97caf6850297f8",
          "grade": false,
          "grade_id": "cell-4ca6c5e51302fd10",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "YtvFI_Wi3N8h"
      },
      "source": [
        "# use create_model to create a model \n",
        "\n",
        "# YOUR CODE HERE\n",
        "model = create_model(n_layers = 2, first_layer_nodes = 500, \n",
        "                     last_layer_nodes = 100, act_funct = 'relu', \n",
        "                     negative_node_incrementation = True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKgMAxSL3N8h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f5c7a33-6316-4571-e0c8-98744fed2ccc"
      },
      "source": [
        "# run model.summary() and make sure that you understand the model architecture that you just built \n",
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_20 (Dense)             (None, 500)               392500    \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 10)                5010      \n",
            "=================================================================\n",
            "Total params: 397,510\n",
            "Trainable params: 397,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ-ky1yt3N8h"
      },
      "source": [
        "# define the grid search parameters\n",
        "param_grid = {'n_layers': [2, 3],\n",
        "              'epochs': [3], \n",
        "              \"first_layer_nodes\": [500, 300],\n",
        "              \"last_layer_nodes\": [100, 50]\n",
        "             }"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIqFIjI93N8h"
      },
      "source": [
        "model = KerasClassifier(create_model)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca0FRafV3N8i"
      },
      "source": [
        "# Create Grid Search\n",
        "grid = GridSearchCV(estimator=model, \n",
        "                    param_grid=param_grid, \n",
        "                    n_jobs=-1, \n",
        "                    verbose=1, \n",
        "                    cv=3)\n",
        "\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "# Report Results\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3srSnrZr3N8i"
      },
      "source": [
        "best_model = grid_result.best_estimator_"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7Ts_DcI3N8i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a21ab53-bc15-40ae-8426-25a476f9ff8b"
      },
      "source": [
        "best_model.get_params()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'build_fn': <function __main__.create_model>,\n",
              " 'epochs': 3,\n",
              " 'first_layer_nodes': 500,\n",
              " 'last_layer_nodes': 100,\n",
              " 'n_layers': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kxzVe6a3N8j"
      },
      "source": [
        "-----\n",
        "\n",
        "# Experiment 2\n",
        "\n",
        "## Benchmark different Optimization Algorithms \n",
        "\n",
        "In this section, we are going to use the same model and dataset in order to benchmark 3 different gridsearch approaches: \n",
        "\n",
        "- Random Search\n",
        "- Bayesian Optimization. \n",
        "- Brute Force Gridsearch\n",
        "\n",
        "Our goal in this experiment is two-fold. We want to see which appraoch \n",
        "\n",
        "- Scores the highest accuracy\n",
        "- Has the shortest run time \n",
        "\n",
        "We want to see how these 3 gridsearch approaches handle these trade-offs and to give you a sense of those trades offs.\n",
        "\n",
        "### Trade-offs\n",
        "\n",
        "`Brute Force Gridsearch` will train a model on every single unique hyperparameter combination, this guarantees that you'll get the highest possible accuracy from your parameter set but your gridsearch might have a very long run-time. \n",
        "\n",
        "`Random Search` will randomly sample from your parameter set which, depending on how many samples, the run-time might be significantly cut down but you might or might not sample the parameters that correspond to the heightest possible accuracies. \n",
        "\n",
        "`Bayesian Optimization` has a bit of intelligence built into it's search algorithm but you do need to manually select some parameters which greatly influence the model learning outcomes. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPm8QDvV3N8k"
      },
      "source": [
        "-------\n",
        "### Build our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6_sKrco3N8k"
      },
      "source": [
        "# because gridsearching can take a lot of time and we are bench marking 3 different approaches\n",
        "# let's build a simple model to minimize run time \n",
        "\n",
        "def build_model(hp):\n",
        "    \n",
        "    \"\"\"\n",
        "    Returns a compiled keras model ready for keras-tuner gridsearch algorithms \n",
        "    \"\"\"\n",
        "    \n",
        "    model = Sequential()\n",
        "    \n",
        "    # hidden layer\n",
        "    model.add(Dense(units=hp.get('units'),activation=hp.get(\"activation\")))\n",
        "    \n",
        "    # output layer\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    \n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(hp.get('learning_rate')),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy'])\n",
        "    \n",
        "    return model\n",
        "  "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxiw2W933N8l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "454d71bc-11f8-440e-f8bc-98453e0c1403"
      },
      "source": [
        "# build out our hyperparameter dictionary \n",
        "hp = HyperParameters()\n",
        "hp.Int('units', min_value=32, max_value=512, step=32)\n",
        "hp.Choice('learning_rate',values=[1e-1, 1e-2, 1e-3])\n",
        "hp.Choice('activation',values=[\"relu\", \"sigmoid\"])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'relu'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uun50jtA3N8l"
      },
      "source": [
        "------\n",
        "# Run the Gridsearch Algorithms \n",
        "\n",
        "### Random Search\n",
        "\n",
        "Be sure to check out the [**docs for Keras-Tuner**](https://keras-team.github.io/keras-tuner/documentation/tuners/). Here you can read about the input parameters for the `RandomSearch` tuner."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "aaff9aae33845f374e15f2381719d83a",
          "grade": false,
          "grade_id": "cell-8c1dfb9b6d12bea2",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "1JAYUV043N8l"
      },
      "source": [
        "# how many unique hyperparameter combinations do we have? \n",
        "# HINT: take the product of the number of possible values for each hyperparameter \n",
        "# save your answer to n_unique_hparam_combos\n",
        "\n",
        "# YOUR CODE HERE\n",
        "n_unique_hparam_combos = 16 * 3 * 2"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a9d628451e83431e1b52da10eccf2c00",
          "grade": false,
          "grade_id": "cell-1fa83950bb2d5f92",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "tL0DEryA3N8l"
      },
      "source": [
        "# how many of these do we want to randomly sample?\n",
        "# let's pick 25% of n_unique_hparam_combos param combos to sample\n",
        "# save this number to n_param_combos_to_sample\n",
        "\n",
        "# YOUR CODE HERE\n",
        "n_param_combos_to_sample = n_unique_hparam_combos * 0.25"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7s1B64fM3N8m"
      },
      "source": [
        "random_tuner = RandomSearch(\n",
        "            build_model,\n",
        "            objective='val_accuracy',\n",
        "            max_trials=n_param_combos_to_sample, # number of times to sample the parameter set and build a model \n",
        "            seed=1234,\n",
        "            hyperparameters=hp, # pass in our hyperparameter dictionary\n",
        "            directory='./keras-tuner-trial',\n",
        "            project_name='random_search')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckrdGsa33N8m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0534f01-765f-4091-982a-ee2d1b85c27f"
      },
      "source": [
        "# take note of Total elapsed time in print out\n",
        "random_tuner.search(X_train, y_train,\n",
        "                    epochs=3,\n",
        "                    validation_data=(X_test, y_test))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 24 Complete [00h 00m 19s]\n",
            "val_accuracy: 0.7057600021362305\n",
            "\n",
            "Best val_accuracy So Far: 0.8704800009727478\n",
            "Total elapsed time: 00h 08m 21s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qBo2JTp3N8m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75741434-3426-4113-c0e4-9c19314c659b"
      },
      "source": [
        "# identify the best score and hyperparamter (should be at the top since scores are ranked)\n",
        "random_tuner.results_summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results summary\n",
            "Results in ./keras-tuner-trial/random_search\n",
            "Showing 10 best trials\n",
            "Objective(name='val_accuracy', direction='max')\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 384\n",
            "learning_rate: 0.001\n",
            "activation: relu\n",
            "Score: 0.8704800009727478\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 352\n",
            "learning_rate: 0.001\n",
            "activation: relu\n",
            "Score: 0.8693600296974182\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 480\n",
            "learning_rate: 0.001\n",
            "activation: sigmoid\n",
            "Score: 0.8578000068664551\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 448\n",
            "learning_rate: 0.001\n",
            "activation: sigmoid\n",
            "Score: 0.8576800227165222\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 288\n",
            "learning_rate: 0.001\n",
            "activation: sigmoid\n",
            "Score: 0.8545600175857544\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 224\n",
            "learning_rate: 0.001\n",
            "activation: sigmoid\n",
            "Score: 0.8539599776268005\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 416\n",
            "learning_rate: 0.001\n",
            "activation: sigmoid\n",
            "Score: 0.8501600027084351\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 160\n",
            "learning_rate: 0.01\n",
            "activation: sigmoid\n",
            "Score: 0.8362399935722351\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 192\n",
            "learning_rate: 0.01\n",
            "activation: sigmoid\n",
            "Score: 0.8342400193214417\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 320\n",
            "learning_rate: 0.01\n",
            "activation: sigmoid\n",
            "Score: 0.8314399719238281\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "i64jjqF43N8m"
      },
      "source": [
        " ### Results\n",
        " \n",
        "Identify and write the the best performing hyperparamter combination and model score. \n",
        "Note that because this is Random Search, multiple runs might have slighly different outcomes. \n",
        " \n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f084b5d373f8589a1de8d6d4473b974a",
          "grade": true,
          "grade_id": "cell-5527738b6382c164",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "fZpw8Jc43N8m"
      },
      "source": [
        "The best performing hyperparameter combination from this RandomSearch run has:\n",
        "384 units, learning_rate of 0.001, and uses the relu activation function in the hidden layers. The validation accuracy score is: 0.8704800009727478."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeZbiHHW3N8m"
      },
      "source": [
        "------\n",
        "### Bayesian Optimization\n",
        "\n",
        "![](https://upload.wikimedia.org/wikipedia/commons/0/02/GpParBayesAnimationSmall.gif)\n",
        "\n",
        "Be sure to check out the [**docs for Keras-Tuner**](https://keras-team.github.io/keras-tuner/documentation/tuners/). Here you can read about the input parameters for the `BayesianOptimization` tuner.\n",
        "\n",
        "Pay special attention to these `BayesianOptimization` parameters: `num_initial_points` and `beta`. \n",
        "\n",
        "`num_initial_points`: \n",
        "\n",
        "Number of randomly selected hyperparameter combinations to try before applying bayesian probability to determine liklihood of which param combo to try next based on expected improvement\n",
        "\n",
        "\n",
        "`beta`: \n",
        "\n",
        "Larger values means more willing to explore new hyperparameter combinations (analogous to searching for the global minimum in Gradient Descent), smaller values means that it is less willing to try new hyperparameter combinations (analogous to getting stuck in a local minimum in Gradient Descent). \n",
        "\n",
        "As a start, error on the side of larger values. What defines a small or large value you ask? That question would pull us into the mathematical intricacies of Bayesian Optimization and Gaussian Processes. For simplicity, notice that the default value is 2.6 and work from there. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqTPk72C3N8n"
      },
      "source": [
        "# we know that 24 samples is about 25% of 96 possible hyper-parameter combos\n",
        "# because BO isn't random (after num_initial_points number of trails) let's see if 15 max trials gives good results\n",
        "# feel free to play with any of these numbers\n",
        "max_trials=20\n",
        "num_initial_points=7\n",
        "beta=7.5"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9DIaa023N8n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29597501-f757-4e99-b1f0-c26facce75f9"
      },
      "source": [
        "bayesian_tuner = BayesianOptimization(\n",
        "                    build_model,\n",
        "                    objective='val_accuracy',\n",
        "                    max_trials=max_trials,\n",
        "                    hyperparameters=hp, # pass in our hyperparameter dictionary\n",
        "                    num_initial_points=num_initial_points, \n",
        "                    beta=beta, \n",
        "                    seed=1234,\n",
        "                    directory='./keras-tuner-trial',\n",
        "                    project_name='bayesian_optimization_4')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reloading Oracle from existing project ./keras-tuner-trial/bayesian_optimization_4/oracle.json\n",
            "INFO:tensorflow:Reloading Tuner from ./keras-tuner-trial/bayesian_optimization_4/tuner0.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDz54fB33N8n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3e15351-25bf-4407-83f7-d866281ef419"
      },
      "source": [
        "bayesian_tuner.search(X_train, y_train,\n",
        "               epochs=3,\n",
        "               validation_data=(X_test, y_test))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 5 Complete [00h 00m 20s]\n",
            "val_accuracy: 0.8496000170707703\n",
            "\n",
            "Best val_accuracy So Far: 0.8723199963569641\n",
            "Total elapsed time: 00h 02m 14s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "LtWSNvA63N8n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6e817a3-ef4d-49cf-dd68-e1e6e83c9063"
      },
      "source": [
        "bayesian_tuner.results_summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results summary\n",
            "Results in ./keras-tuner-trial/bayesian_optimization_4\n",
            "Showing 10 best trials\n",
            "Objective(name='val_accuracy', direction='max')\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 352\n",
            "learning_rate: 0.001\n",
            "activation: relu\n",
            "Score: 0.8723199963569641\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 512\n",
            "learning_rate: 0.001\n",
            "activation: relu\n",
            "Score: 0.8671200275421143\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 480\n",
            "learning_rate: 0.001\n",
            "activation: sigmoid\n",
            "Score: 0.8565599918365479\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 224\n",
            "learning_rate: 0.001\n",
            "activation: sigmoid\n",
            "Score: 0.8559600114822388\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 256\n",
            "learning_rate: 0.001\n",
            "activation: sigmoid\n",
            "Score: 0.8544399738311768\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 192\n",
            "learning_rate: 0.001\n",
            "activation: sigmoid\n",
            "Score: 0.8542799949645996\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 192\n",
            "learning_rate: 0.001\n",
            "activation: sigmoid\n",
            "Score: 0.8523600101470947\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 512\n",
            "learning_rate: 0.001\n",
            "activation: sigmoid\n",
            "Score: 0.8520799875259399\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 192\n",
            "learning_rate: 0.001\n",
            "activation: sigmoid\n",
            "Score: 0.8515599966049194\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 192\n",
            "learning_rate: 0.001\n",
            "activation: sigmoid\n",
            "Score: 0.8508800268173218\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FK6t70uR3N8n"
      },
      "source": [
        " ### Results\n",
        " \n",
        "Identify and write the the best performing hyperparamter combination and model score. \n",
        "Note that because this is  Bayesian Optimization, multiple runs might have slighly different outcomes. \n",
        " \n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "1badcdca408cdd49bc2e409dca3bac5a",
          "grade": true,
          "grade_id": "cell-ff95600bf745f40f",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "62JAn9nr3N8n"
      },
      "source": [
        "The best performing hyperparameter combination from this BayesianSearch run has: 352 units, learning_rate of 0.001, and uses the relu activation function in the hidden layers. The validation accuracy score is: 0.8723199963569641 (an improvement of 0.0019 over RandomSearch)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4uvhgYr3N8n"
      },
      "source": [
        "---------\n",
        "## Brute Force Gridsearch Optimization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RXHLCUe3N8n"
      },
      "source": [
        "### Populate a Sklearn compatiable parameter dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SERKuNo83N8o"
      },
      "source": [
        "# build out our hyperparameter dictionary \n",
        "hyper_parameters = {\n",
        "    # BUG Fix: cast array as list otherwise GridSearchCV will throw error\n",
        "    \"units\": np.arange(32, 544, 32).tolist(),\n",
        "    \"learning_rate\": [1e-1, 1e-2, 1e-3],\n",
        "    \"activation\":[\"relu\", \"sigmoid\"]\n",
        "}"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQPU1I5j3N8o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e9f3294-7281-4b0c-eb0c-709b12d69cb4"
      },
      "source": [
        "hyper_parameters"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': ['relu', 'sigmoid'],\n",
              " 'learning_rate': [0.1, 0.01, 0.001],\n",
              " 'units': [32,\n",
              "  64,\n",
              "  96,\n",
              "  128,\n",
              "  160,\n",
              "  192,\n",
              "  224,\n",
              "  256,\n",
              "  288,\n",
              "  320,\n",
              "  352,\n",
              "  384,\n",
              "  416,\n",
              "  448,\n",
              "  480,\n",
              "  512]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcrQUNpS3N8o"
      },
      "source": [
        "### Build a Sklearn compatiable model function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7FkK8-l3N8o"
      },
      "source": [
        "def build_model(units, learning_rate, activation):\n",
        "    \n",
        "    \"\"\"\n",
        "    Returns a complie keras model ready for keras-tuner gridsearch algorithms \n",
        "    \"\"\"\n",
        "    \n",
        "    model = Sequential()\n",
        "    \n",
        "    # hidden layer\n",
        "    model.add(Dense(units, activation=activation))\n",
        "    \n",
        "    # output layer\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    \n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKiMGEhz3N8o"
      },
      "source": [
        "model = KerasClassifier(build_fn = build_model)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "0MoNLuKm3N8o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5887b45-55c2-4084-9321-9dd3d885d54f"
      },
      "source": [
        "# save start time \n",
        "start = time()\n",
        "\n",
        "# Create Grid Search\n",
        "grid = GridSearchCV(estimator=model, \n",
        "                    param_grid=hyper_parameters, \n",
        "                    n_jobs=-1, \n",
        "                    verbose=1, \n",
        "                    cv=3)\n",
        "\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "# save end time \n",
        "end = time()\n",
        "\n",
        "# Report Results\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 96 candidates, totalling 288 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  3.8min\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed: 15.9min\n",
            "[Parallel(n_jobs=-1)]: Done 288 out of 288 | elapsed: 23.1min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2344/2344 [==============================] - 5s 2ms/step - loss: 0.6160 - accuracy: 0.8172\n",
            "Best: 0.8449199994405111 using {'activation': 'relu', 'learning_rate': 0.001, 'units': 416}\n",
            "Means: 0.28622666001319885, Stdev: 0.04521385512989778 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 32}\n",
            "Means: 0.3094133337338765, Stdev: 0.011542946082687123 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 64}\n",
            "Means: 0.3131866653760274, Stdev: 0.02457899867993831 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 96}\n",
            "Means: 0.23090667029221854, Stdev: 0.07574910348462352 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 128}\n",
            "Means: 0.25174666941165924, Stdev: 0.047277158087758876 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 160}\n",
            "Means: 0.302306666970253, Stdev: 0.04478863416826123 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 192}\n",
            "Means: 0.26472000281016034, Stdev: 0.07412621532392441 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 224}\n",
            "Means: 0.26395999391873676, Stdev: 0.030696568082914436 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 256}\n",
            "Means: 0.27609332899252575, Stdev: 0.06067606650663392 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 288}\n",
            "Means: 0.2994399964809418, Stdev: 0.0223683516734871 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 320}\n",
            "Means: 0.298813338081042, Stdev: 0.042793301562027965 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 352}\n",
            "Means: 0.3251466751098633, Stdev: 0.02400198101817906 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 384}\n",
            "Means: 0.25828000406424206, Stdev: 0.03565148937688746 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 416}\n",
            "Means: 0.2699333280324936, Stdev: 0.06110453569136163 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 448}\n",
            "Means: 0.23445333540439606, Stdev: 0.020923571912993256 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 480}\n",
            "Means: 0.29283999900023144, Stdev: 0.04057396458832588 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 512}\n",
            "Means: 0.7851466735204061, Stdev: 0.007130412138920619 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 32}\n",
            "Means: 0.7910666664441427, Stdev: 0.006289065768604655 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 64}\n",
            "Means: 0.7997999787330627, Stdev: 0.004366170024407232 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 96}\n",
            "Means: 0.8122133215268453, Stdev: 0.003762892572100215 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 128}\n",
            "Means: 0.803933322429657, Stdev: 0.00223338471041364 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 160}\n",
            "Means: 0.8090666731198629, Stdev: 0.007849883903670226 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 192}\n",
            "Means: 0.7991600036621094, Stdev: 0.006056103376634561 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 224}\n",
            "Means: 0.7985333204269409, Stdev: 0.005925243350006973 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 256}\n",
            "Means: 0.8079333305358887, Stdev: 0.009847760905913607 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 288}\n",
            "Means: 0.8065599997838339, Stdev: 0.004654572124090443 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 320}\n",
            "Means: 0.8026000062624613, Stdev: 0.004974198192565696 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 352}\n",
            "Means: 0.8046799898147583, Stdev: 0.010143140139525197 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 384}\n",
            "Means: 0.8001466592152914, Stdev: 0.002201911237844658 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 416}\n",
            "Means: 0.8053333361943563, Stdev: 0.005509494900394133 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 448}\n",
            "Means: 0.8063466548919678, Stdev: 0.0013332078971933974 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 480}\n",
            "Means: 0.8036266764005026, Stdev: 0.000918169245176889 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 512}\n",
            "Means: 0.7884666721026102, Stdev: 0.006111548379803 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 32}\n",
            "Means: 0.811906655629476, Stdev: 0.0012282723015269745 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 64}\n",
            "Means: 0.819920003414154, Stdev: 0.0032566589344164933 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 96}\n",
            "Means: 0.8278400103251139, Stdev: 0.0030538211827962035 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 128}\n",
            "Means: 0.8298133214314779, Stdev: 0.003545106738660841 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 160}\n",
            "Means: 0.8305866718292236, Stdev: 0.0015718586781544434 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 192}\n",
            "Means: 0.8344266812006632, Stdev: 0.004064328548308885 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 224}\n",
            "Means: 0.8328533371289571, Stdev: 0.002211558532162242 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 256}\n",
            "Means: 0.8374399940172831, Stdev: 0.0028244628973994033 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 288}\n",
            "Means: 0.8369599978129069, Stdev: 0.002372508715558226 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 320}\n",
            "Means: 0.8395066459973654, Stdev: 0.0027751925382542538 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 352}\n",
            "Means: 0.8412133455276489, Stdev: 0.004709628642735075 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 384}\n",
            "Means: 0.8449199994405111, Stdev: 0.0011060982824698772 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 416}\n",
            "Means: 0.8400933345158895, Stdev: 0.0015424006854030795 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 448}\n",
            "Means: 0.8434799909591675, Stdev: 0.0017855589454161642 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 480}\n",
            "Means: 0.8441733320554098, Stdev: 0.0027763297054140532 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 512}\n",
            "Means: 0.6614799896876017, Stdev: 0.03508037782154909 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 32}\n",
            "Means: 0.6885333259900411, Stdev: 0.013280435257475107 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 64}\n",
            "Means: 0.692413330078125, Stdev: 0.007350470046365186 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 96}\n",
            "Means: 0.6610399881998698, Stdev: 0.0059911841656272655 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 128}\n",
            "Means: 0.6642533342043558, Stdev: 0.03607193118086374 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 160}\n",
            "Means: 0.6384666760762533, Stdev: 0.033127698225067594 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 192}\n",
            "Means: 0.6212133367856344, Stdev: 0.04750681117084058 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 224}\n",
            "Means: 0.621239980061849, Stdev: 0.04763183521052811 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 256}\n",
            "Means: 0.5988933245340983, Stdev: 0.0321012635955393 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 288}\n",
            "Means: 0.6589333415031433, Stdev: 0.02295479937269177 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 320}\n",
            "Means: 0.5912133455276489, Stdev: 0.031125100395533963 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 352}\n",
            "Means: 0.664786676565806, Stdev: 0.012452112780110432 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 384}\n",
            "Means: 0.5869333346684774, Stdev: 0.027076333055516714 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 416}\n",
            "Means: 0.6529600024223328, Stdev: 0.01169701959546614 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 448}\n",
            "Means: 0.5851066807905833, Stdev: 0.06867822344949367 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 480}\n",
            "Means: 0.6102133393287659, Stdev: 0.03750566329094899 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 512}\n",
            "Means: 0.7902400096257528, Stdev: 0.0013270604406595114 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 32}\n",
            "Means: 0.8084266781806946, Stdev: 0.0011268263386320983 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 64}\n",
            "Means: 0.8090133269627889, Stdev: 0.005623405392890132 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 96}\n",
            "Means: 0.8111733198165894, Stdev: 0.003886704433633194 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 128}\n",
            "Means: 0.8184933463732401, Stdev: 0.002340911941868706 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 160}\n",
            "Means: 0.8170266548792521, Stdev: 0.005042791171740072 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 192}\n",
            "Means: 0.8152000109354655, Stdev: 0.0070932226828107 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 224}\n",
            "Means: 0.8122000098228455, Stdev: 0.007783951131666716 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 256}\n",
            "Means: 0.818613330523173, Stdev: 0.008150649646069812 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 288}\n",
            "Means: 0.8204933206240336, Stdev: 0.006005901082161203 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 320}\n",
            "Means: 0.8196400006612142, Stdev: 0.002643845001446355 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 352}\n",
            "Means: 0.8165466785430908, Stdev: 0.003728425194954841 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 384}\n",
            "Means: 0.8188399871190389, Stdev: 0.0016898184548894896 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 416}\n",
            "Means: 0.8205066521962484, Stdev: 0.008286999782071694 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 448}\n",
            "Means: 0.8157733281453451, Stdev: 0.0016347375876106856 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 480}\n",
            "Means: 0.8087999820709229, Stdev: 0.009950976391502053 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 512}\n",
            "Means: 0.7606933315594991, Stdev: 0.002352059881790116 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 32}\n",
            "Means: 0.7787333329518636, Stdev: 0.002666193067752121 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 64}\n",
            "Means: 0.787773331006368, Stdev: 0.0009450563689420074 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 96}\n",
            "Means: 0.7931199868520101, Stdev: 0.0009737836432149259 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 128}\n",
            "Means: 0.7934266924858093, Stdev: 0.0020242096938605948 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 160}\n",
            "Means: 0.7979466716448466, Stdev: 0.0017282911383468796 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 192}\n",
            "Means: 0.7965066830317179, Stdev: 0.0012942264617253035 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 224}\n",
            "Means: 0.7981200019518534, Stdev: 0.0018897418998909186 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 256}\n",
            "Means: 0.7974533438682556, Stdev: 0.003559977340314122 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 288}\n",
            "Means: 0.8000133236249288, Stdev: 0.005811280293904701 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 320}\n",
            "Means: 0.7997600038846334, Stdev: 0.0018752952996775726 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 352}\n",
            "Means: 0.8016533454259237, Stdev: 0.004045109275608768 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 384}\n",
            "Means: 0.802946666876475, Stdev: 0.0017751769680820662 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 416}\n",
            "Means: 0.8008400003115336, Stdev: 0.0034041669385628647 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 448}\n",
            "Means: 0.8026533524195353, Stdev: 0.0042423063657144 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 480}\n",
            "Means: 0.7952933311462402, Stdev: 0.00930230549779171 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 512}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htJcEnxL3N8o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "406c2d3c-8fe9-44cc-b1ed-210d0b48c442"
      },
      "source": [
        "# total run time \n",
        "total_run_time_in_miniutes = (end - start)/60\n",
        "total_run_time_in_miniutes"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23.227677766482035"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqcmHN6-3N8o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17f8f1c7-7286-4a68-d3dd-31557e0a77ab"
      },
      "source": [
        "grid_result.best_params_"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': 'relu', 'learning_rate': 0.001, 'units': 416}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRbvUb8G3N8p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9914d199-3f48-49fb-d77f-9d2a6e5419b3"
      },
      "source": [
        "# because all other optimization approaches are reporting test set score\n",
        "# let's calculate the test set score in this case \n",
        "best_model = grid_result.best_estimator_\n",
        "test_acc = best_model.score(X_test, y_test)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 1s 2ms/step - loss: 0.5068 - accuracy: 0.8521\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LaeUxSc3N8p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c4f9051-91be-4969-9100-42927075a7e7"
      },
      "source": [
        "test_acc"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8521199822425842"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JxhrZQM3N8p"
      },
      "source": [
        " ### Results\n",
        " \n",
        "Identify and write the the best performing hyperparamter combination and model score. \n",
        " \n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "9577db883482c6cded3836e5cfbf5a74",
          "grade": true,
          "grade_id": "cell-eb06d682d2790f6e",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "v-w_ijvV3N8p"
      },
      "source": [
        "The best performing hyperparameter combination from this Bruteforce Gridsearch has: 416 units, learning_rate of 0.001, and uses the relu activation function in the hidden layers. The validation accuracy score is: 0.8521199822425842. This is worse than both the RandomSearch and the Bayesian Search methods and only a slight improvement over the manual approach we took yesterday."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Up3qBtOz3N8p"
      },
      "source": [
        "_______\n",
        "\n",
        "# Conclusion\n",
        "\n",
        "The spirit of this experiment is to expose you to the idea of benchmarking and comparing the trade-offs of various gridsearch approaches. \n",
        "\n",
        "Even if we did find a way to pass in the original test set into GridSearchCV, we can see that both Random Search and Bayesian Optimization are arguably better alternatives to a brute force grid search when we consider the trade-offs of run time and locating the best performing model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKgiVHk23N8p"
      },
      "source": [
        "----\n",
        "\n",
        "# Stretch Goals\n",
        "\n",
        "- Feel free to run whatever gridserach experiments on whatever models you like!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xH_z67L3N8p"
      },
      "source": [
        "# this is your open playground - be free to explore as you wish "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}